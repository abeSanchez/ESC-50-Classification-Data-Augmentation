{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "c:\\programdata\\miniconda3\\lib\\site-packages\\librosa\\util\\decorators.py:9: NumbaDeprecationWarning: \u001b[1mAn import was requested from a module that has moved location.\n",
      "Import requested from: 'numba.decorators', please update to use 'numba.core.decorators' or pin to Numba version 0.48.0. This alias will not be present in Numba version 0.50.0.\u001b[0m\n",
      "  from numba.decorators import jit as optional_jit\n",
      "c:\\programdata\\miniconda3\\lib\\site-packages\\librosa\\util\\decorators.py:9: NumbaDeprecationWarning: \u001b[1mAn import was requested from a module that has moved location.\n",
      "Import of 'jit' requested from: 'numba.decorators', please update to use 'numba.core.decorators' or pin to Numba version 0.48.0. This alias will not be present in Numba version 0.50.0.\u001b[0m\n",
      "  from numba.decorators import jit as optional_jit\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import keras\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "import librosa\n",
    "import librosa.display\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import random\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, accuracy_score\n",
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1337)\n",
    "random.seed(1337)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read ESC-50 metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_data = pd.read_csv('./ESC-50-master/meta/esc50.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2000, 7)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>fold</th>\n",
       "      <th>target</th>\n",
       "      <th>category</th>\n",
       "      <th>esc10</th>\n",
       "      <th>src_file</th>\n",
       "      <th>take</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1-100032-A-0.wav</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>dog</td>\n",
       "      <td>True</td>\n",
       "      <td>100032</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1-100038-A-14.wav</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>chirping_birds</td>\n",
       "      <td>False</td>\n",
       "      <td>100038</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1-100210-A-36.wav</td>\n",
       "      <td>1</td>\n",
       "      <td>36</td>\n",
       "      <td>vacuum_cleaner</td>\n",
       "      <td>False</td>\n",
       "      <td>100210</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1-100210-B-36.wav</td>\n",
       "      <td>1</td>\n",
       "      <td>36</td>\n",
       "      <td>vacuum_cleaner</td>\n",
       "      <td>False</td>\n",
       "      <td>100210</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1-101296-A-19.wav</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>thunderstorm</td>\n",
       "      <td>False</td>\n",
       "      <td>101296</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            filename  fold  target        category  esc10  src_file take\n",
       "0   1-100032-A-0.wav     1       0             dog   True    100032    A\n",
       "1  1-100038-A-14.wav     1      14  chirping_birds  False    100038    A\n",
       "2  1-100210-A-36.wav     1      36  vacuum_cleaner  False    100210    A\n",
       "3  1-100210-B-36.wav     1      36  vacuum_cleaner  False    100210    B\n",
       "4  1-101296-A-19.wav     1      19    thunderstorm  False    101296    A"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(meta_data.shape)\n",
    "meta_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing a dog audio sample via melspectrogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(128, 216)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y, sr = librosa.load('./ESC-50-master/audio/1-100032-A-0.wav')\n",
    "ps = librosa.feature.melspectrogram(y=y, sr=sr)\n",
    "ps.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.colorbar.Colorbar at 0x1ecd242c948>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "librosa.display.specshow(ps, x_axis='time', y_axis='mel')\n",
    "plt.colorbar(format='%+2.0f dB')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split dataset into train, validation, and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames = meta_data['filename']\n",
    "labels = meta_data['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_val, x_test_names, y_train_val, y_test = train_test_split(filenames, labels, random_state=1337, stratify=labels, test_size=.15)\n",
    "x_train_names, x_val_names, y_train, y_val = train_test_split(x_train_val, y_train_val, random_state=1337, stratify=y_train_val, test_size=0.117647058823529)\n",
    "\n",
    "x_train_names = np.array(x_train_names)\n",
    "x_val_names = np.array(x_val_names)\n",
    "x_test_names = np.array(x_test_names)\n",
    "\n",
    "y_train = np.array(y_train)\n",
    "y_val = np.array(y_val)\n",
    "y_test = np.array(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load dataset without augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = []\n",
    "x_val = []\n",
    "x_test = []\n",
    "\n",
    "for name in x_train_names:\n",
    "    y, sr = librosa.load('./ESC-50-master/audio/' + name, duration=4.67)  \n",
    "    ps = librosa.feature.melspectrogram(y=y, sr=sr)\n",
    "    assert ps.shape == (128, 202)\n",
    "    x_train.append(ps)\n",
    "    \n",
    "for name in x_val_names:\n",
    "    y, sr = librosa.load('./ESC-50-master/audio/' + name, duration=4.67)  \n",
    "    ps = librosa.feature.melspectrogram(y=y, sr=sr)\n",
    "    assert ps.shape == (128, 202)\n",
    "    x_val.append(ps)\n",
    "\n",
    "for name in x_test_names:\n",
    "    y, sr = librosa.load('./ESC-50-master/audio/' + name, duration=4.67)  \n",
    "    ps = librosa.feature.melspectrogram(y=y, sr=sr)\n",
    "    assert ps.shape == (128, 202)\n",
    "    x_test.append(ps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_ = np.array([x.reshape( (128, 202, 1) ) for x in x_train])\n",
    "x_val_ = np.array([x.reshape( (128, 202, 1) ) for x in x_val])\n",
    "x_test_ = np.array([x.reshape( (128, 202, 1) ) for x in x_test])\n",
    "\n",
    "y_train_ = np.array(keras.utils.to_categorical(y_train, 50))\n",
    "y_val_ = np.array(keras.utils.to_categorical(y_val, 50))\n",
    "y_test_ = np.array(keras.utils.to_categorical(y_test, 50))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load in ResNet50 architecture with new weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.applications.resnet_v2.ResNet50V2(include_top=True, weights=None, input_tensor=None, input_shape=(128,202,1), pooling=None, classes=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1500 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "1500/1500 [==============================] - 50s 33ms/step - loss: 4.0710 - accuracy: 0.0380 - val_loss: 98.7875 - val_accuracy: 0.0250\n",
      "Epoch 2/20\n",
      "1500/1500 [==============================] - 31s 21ms/step - loss: 3.5734 - accuracy: 0.0807 - val_loss: 5.8239 - val_accuracy: 0.0600\n",
      "Epoch 3/20\n",
      "1500/1500 [==============================] - 31s 21ms/step - loss: 3.2456 - accuracy: 0.1180 - val_loss: 4.4620 - val_accuracy: 0.0400\n",
      "Epoch 4/20\n",
      "1500/1500 [==============================] - 31s 21ms/step - loss: 3.0266 - accuracy: 0.1647 - val_loss: 4.8320 - val_accuracy: 0.0650\n",
      "Epoch 5/20\n",
      "1500/1500 [==============================] - 31s 21ms/step - loss: 2.6654 - accuracy: 0.2533 - val_loss: 5.7349 - val_accuracy: 0.0950\n",
      "Epoch 6/20\n",
      "1500/1500 [==============================] - 31s 21ms/step - loss: 2.3654 - accuracy: 0.3080 - val_loss: 16.0040 - val_accuracy: 0.0600\n",
      "Epoch 7/20\n",
      "1500/1500 [==============================] - 31s 21ms/step - loss: 2.2464 - accuracy: 0.3313 - val_loss: 26.4028 - val_accuracy: 0.0650\n",
      "Epoch 8/20\n",
      "1500/1500 [==============================] - 31s 21ms/step - loss: 2.0900 - accuracy: 0.3727 - val_loss: 18.0706 - val_accuracy: 0.0900\n",
      "Epoch 9/20\n",
      "1500/1500 [==============================] - 31s 21ms/step - loss: 1.7668 - accuracy: 0.4640 - val_loss: 14.8093 - val_accuracy: 0.0450\n",
      "Epoch 10/20\n",
      "1500/1500 [==============================] - 31s 21ms/step - loss: 1.7468 - accuracy: 0.4780 - val_loss: 9.9902 - val_accuracy: 0.0800\n",
      "Epoch 11/20\n",
      "1500/1500 [==============================] - 31s 21ms/step - loss: 1.5150 - accuracy: 0.5353 - val_loss: 8.9905 - val_accuracy: 0.1300\n",
      "Epoch 12/20\n",
      "1500/1500 [==============================] - 31s 21ms/step - loss: 1.3710 - accuracy: 0.5840 - val_loss: 26.7509 - val_accuracy: 0.0550\n",
      "Epoch 13/20\n",
      "1500/1500 [==============================] - 31s 21ms/step - loss: 1.2924 - accuracy: 0.6000 - val_loss: 24.5940 - val_accuracy: 0.0600\n",
      "Epoch 14/20\n",
      "1500/1500 [==============================] - 31s 21ms/step - loss: 1.1836 - accuracy: 0.6320 - val_loss: 14.2612 - val_accuracy: 0.0700\n",
      "Epoch 15/20\n",
      "1500/1500 [==============================] - 31s 21ms/step - loss: 1.1089 - accuracy: 0.6440 - val_loss: 11.4966 - val_accuracy: 0.0600\n",
      "Epoch 16/20\n",
      "1500/1500 [==============================] - 31s 21ms/step - loss: 0.9571 - accuracy: 0.6907 - val_loss: 16.3871 - val_accuracy: 0.0450\n",
      "Epoch 17/20\n",
      "1500/1500 [==============================] - 31s 21ms/step - loss: 0.9242 - accuracy: 0.7080 - val_loss: 17.8429 - val_accuracy: 0.0500\n",
      "Epoch 18/20\n",
      "1500/1500 [==============================] - 31s 21ms/step - loss: 0.8652 - accuracy: 0.7213 - val_loss: 15.5292 - val_accuracy: 0.0650\n",
      "Epoch 19/20\n",
      "1500/1500 [==============================] - 31s 21ms/step - loss: 0.8069 - accuracy: 0.7393 - val_loss: 11.1096 - val_accuracy: 0.0750\n",
      "Epoch 20/20\n",
      "1500/1500 [==============================] - 31s 21ms/step - loss: 0.6945 - accuracy: 0.7853 - val_loss: 16.5667 - val_accuracy: 0.0800\n"
     ]
    }
   ],
   "source": [
    "callbacks = [ModelCheckpoint('./models/resnet50v2.h5', monitor='val_loss', verbose=0, \n",
    "                    save_best_only=True, save_weights_only=False, mode='auto', period=1)]\n",
    "\n",
    "history1 = model.fit(x_train_,\n",
    "          y_train_, \n",
    "          epochs=20, \n",
    "          verbose=1,\n",
    "          batch_size=32,\n",
    "          validation_data=(x_val_, y_val_),\n",
    "          callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg16model = keras.applications.vgg16.VGG16(include_top=True, weights=None, input_tensor=None, input_shape=(128,202,1), pooling=None, classes=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg16model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1500 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "1500/1500 [==============================] - 37s 25ms/step - loss: 6.1536 - accuracy: 0.0153 - val_loss: 3.9120 - val_accuracy: 0.0200\n",
      "Epoch 2/20\n",
      "1500/1500 [==============================] - 26s 17ms/step - loss: 3.9171 - accuracy: 0.0233 - val_loss: 3.9121 - val_accuracy: 0.0200\n",
      "Epoch 3/20\n",
      "1500/1500 [==============================] - 26s 17ms/step - loss: 3.9419 - accuracy: 0.0160 - val_loss: 3.7772 - val_accuracy: 0.0450\n",
      "Epoch 4/20\n",
      "1500/1500 [==============================] - 26s 17ms/step - loss: 3.6929 - accuracy: 0.0567 - val_loss: 3.3900 - val_accuracy: 0.0900\n",
      "Epoch 5/20\n",
      "1500/1500 [==============================] - 26s 17ms/step - loss: 3.3320 - accuracy: 0.0900 - val_loss: 3.1971 - val_accuracy: 0.1200\n",
      "Epoch 6/20\n",
      "1500/1500 [==============================] - 26s 17ms/step - loss: 3.1486 - accuracy: 0.1153 - val_loss: 3.3120 - val_accuracy: 0.1100\n",
      "Epoch 7/20\n",
      "1500/1500 [==============================] - 26s 17ms/step - loss: 2.9905 - accuracy: 0.1487 - val_loss: 2.9383 - val_accuracy: 0.1550\n",
      "Epoch 8/20\n",
      "1500/1500 [==============================] - 26s 17ms/step - loss: 2.7869 - accuracy: 0.1853 - val_loss: 2.9410 - val_accuracy: 0.1750\n",
      "Epoch 9/20\n",
      "1500/1500 [==============================] - 26s 17ms/step - loss: 2.7219 - accuracy: 0.2127 - val_loss: 2.7216 - val_accuracy: 0.2200\n",
      "Epoch 10/20\n",
      "1500/1500 [==============================] - 26s 17ms/step - loss: 2.5263 - accuracy: 0.2533 - val_loss: 2.6347 - val_accuracy: 0.2450\n",
      "Epoch 11/20\n",
      "1500/1500 [==============================] - 26s 17ms/step - loss: 2.4128 - accuracy: 0.2707 - val_loss: 2.5396 - val_accuracy: 0.2650\n",
      "Epoch 12/20\n",
      "1500/1500 [==============================] - 26s 17ms/step - loss: 2.2862 - accuracy: 0.3093 - val_loss: 2.4760 - val_accuracy: 0.2700\n",
      "Epoch 13/20\n",
      "1500/1500 [==============================] - 26s 17ms/step - loss: 2.1187 - accuracy: 0.3380 - val_loss: 2.4686 - val_accuracy: 0.2800\n",
      "Epoch 14/20\n",
      "1500/1500 [==============================] - 26s 17ms/step - loss: 1.9977 - accuracy: 0.3907 - val_loss: 2.5298 - val_accuracy: 0.2300\n",
      "Epoch 15/20\n",
      "1500/1500 [==============================] - 26s 17ms/step - loss: 1.9335 - accuracy: 0.4053 - val_loss: 2.3450 - val_accuracy: 0.3100\n",
      "Epoch 16/20\n",
      "1500/1500 [==============================] - 26s 17ms/step - loss: 1.7780 - accuracy: 0.4467 - val_loss: 2.4033 - val_accuracy: 0.3100\n",
      "Epoch 17/20\n",
      "1500/1500 [==============================] - 26s 17ms/step - loss: 1.6083 - accuracy: 0.4813 - val_loss: 2.4962 - val_accuracy: 0.3350\n",
      "Epoch 18/20\n",
      "1500/1500 [==============================] - 26s 17ms/step - loss: 1.4157 - accuracy: 0.5467 - val_loss: 2.5944 - val_accuracy: 0.3300\n",
      "Epoch 19/20\n",
      "1500/1500 [==============================] - 26s 17ms/step - loss: 1.3055 - accuracy: 0.5860 - val_loss: 2.3737 - val_accuracy: 0.3600\n",
      "Epoch 20/20\n",
      "1500/1500 [==============================] - 26s 17ms/step - loss: 1.2029 - accuracy: 0.6027 - val_loss: 2.6463 - val_accuracy: 0.3300\n"
     ]
    }
   ],
   "source": [
    "vgg16model_callbacks = [ModelCheckpoint('./models/vgg16.h5', monitor='val_loss', verbose=0, \n",
    "                    save_best_only=True, save_weights_only=False, mode='auto', period=1)]\n",
    "\n",
    "vgg16model_history = vgg16model.fit(x_train_,\n",
    "          y_train_, \n",
    "          epochs=20, \n",
    "          verbose=1,\n",
    "          batch_size=32,\n",
    "          validation_data=(x_val_, y_val_),\n",
    "          callbacks=vgg16model_callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "mobilenetmodel = keras.applications.mobilenet.MobileNet(include_top=True, weights=None, input_tensor=None, input_shape=(128,202,1), pooling=None, classes=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "mobilenetmodel.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1500 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "1500/1500 [==============================] - 23s 15ms/step - loss: 3.6282 - accuracy: 0.0960 - val_loss: 4.0140 - val_accuracy: 0.0200\n",
      "Epoch 2/20\n",
      "1500/1500 [==============================] - 14s 9ms/step - loss: 2.9665 - accuracy: 0.1827 - val_loss: 4.4759 - val_accuracy: 0.0200\n",
      "Epoch 3/20\n",
      "1500/1500 [==============================] - 14s 9ms/step - loss: 2.5309 - accuracy: 0.2600 - val_loss: 5.0876 - val_accuracy: 0.0200\n",
      "Epoch 4/20\n",
      "1500/1500 [==============================] - 14s 9ms/step - loss: 2.2474 - accuracy: 0.3427 - val_loss: 5.6272 - val_accuracy: 0.0200\n",
      "Epoch 5/20\n",
      "1500/1500 [==============================] - 14s 9ms/step - loss: 1.8759 - accuracy: 0.4200 - val_loss: 6.1613 - val_accuracy: 0.0200\n",
      "Epoch 6/20\n",
      "1500/1500 [==============================] - 14s 9ms/step - loss: 1.5761 - accuracy: 0.5073 - val_loss: 6.9411 - val_accuracy: 0.0200\n",
      "Epoch 7/20\n",
      "1500/1500 [==============================] - 14s 9ms/step - loss: 1.4083 - accuracy: 0.5687 - val_loss: 7.4621 - val_accuracy: 0.0200\n",
      "Epoch 8/20\n",
      "1500/1500 [==============================] - 14s 9ms/step - loss: 1.2296 - accuracy: 0.6247 - val_loss: 8.2769 - val_accuracy: 0.0200\n",
      "Epoch 9/20\n",
      "1500/1500 [==============================] - 14s 9ms/step - loss: 1.0219 - accuracy: 0.6820 - val_loss: 9.9733 - val_accuracy: 0.0200\n",
      "Epoch 10/20\n",
      "1500/1500 [==============================] - 14s 9ms/step - loss: 0.8550 - accuracy: 0.7173 - val_loss: 9.5902 - val_accuracy: 0.0200\n",
      "Epoch 11/20\n",
      "1500/1500 [==============================] - 14s 9ms/step - loss: 0.7448 - accuracy: 0.7567 - val_loss: 9.0750 - val_accuracy: 0.0200\n",
      "Epoch 12/20\n",
      "1500/1500 [==============================] - 14s 9ms/step - loss: 0.6454 - accuracy: 0.7980 - val_loss: 9.9745 - val_accuracy: 0.0200\n",
      "Epoch 13/20\n",
      "1500/1500 [==============================] - 14s 9ms/step - loss: 0.5665 - accuracy: 0.8233 - val_loss: 10.2020 - val_accuracy: 0.0200\n",
      "Epoch 14/20\n",
      "1500/1500 [==============================] - 14s 10ms/step - loss: 0.4746 - accuracy: 0.8513 - val_loss: 9.9056 - val_accuracy: 0.0400\n",
      "Epoch 15/20\n",
      "1500/1500 [==============================] - 14s 9ms/step - loss: 0.3569 - accuracy: 0.8920 - val_loss: 11.9300 - val_accuracy: 0.0350\n",
      "Epoch 16/20\n",
      "1500/1500 [==============================] - 14s 9ms/step - loss: 0.3338 - accuracy: 0.8993 - val_loss: 5.7361 - val_accuracy: 0.0850\n",
      "Epoch 17/20\n",
      "1500/1500 [==============================] - 14s 9ms/step - loss: 0.3017 - accuracy: 0.9113 - val_loss: 5.9108 - val_accuracy: 0.1650\n",
      "Epoch 18/20\n",
      "1500/1500 [==============================] - 14s 9ms/step - loss: 0.2289 - accuracy: 0.9247 - val_loss: 7.1168 - val_accuracy: 0.0950\n",
      "Epoch 19/20\n",
      "1500/1500 [==============================] - 14s 9ms/step - loss: 0.2322 - accuracy: 0.9293 - val_loss: 5.3723 - val_accuracy: 0.1200\n",
      "Epoch 20/20\n",
      "1500/1500 [==============================] - 14s 9ms/step - loss: 0.1939 - accuracy: 0.9420 - val_loss: 9.9607 - val_accuracy: 0.1000\n"
     ]
    }
   ],
   "source": [
    "mobilenetmodel_callbacks = [ModelCheckpoint('./models/mobilenet.h5', monitor='val_loss', verbose=0, \n",
    "                    save_best_only=True, save_weights_only=False, mode='auto', period=1)]\n",
    "\n",
    "mobilenetmodel_history = mobilenetmodel.fit(x_train_,\n",
    "          y_train_, \n",
    "          epochs=20, \n",
    "          verbose=1,\n",
    "          batch_size=32,\n",
    "          validation_data=(x_val_, y_val_),\n",
    "          callbacks=mobilenetmodel_callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "densenetmodel = keras.applications.densenet.DenseNet121(include_top=True, weights=None, input_tensor=None, input_shape=(128,202,1), pooling=None, classes=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "densenetmodel.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1500 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "1500/1500 [==============================] - 85s 57ms/step - loss: 3.7521 - accuracy: 0.0693 - val_loss: 7.2604 - val_accuracy: 0.0250\n",
      "Epoch 2/20\n",
      "1500/1500 [==============================] - 42s 28ms/step - loss: 3.1361 - accuracy: 0.1587 - val_loss: 6.6286 - val_accuracy: 0.0400\n",
      "Epoch 3/20\n",
      "1500/1500 [==============================] - 42s 28ms/step - loss: 2.7278 - accuracy: 0.2233 - val_loss: 9.0564 - val_accuracy: 0.0500\n",
      "Epoch 4/20\n",
      "1500/1500 [==============================] - 42s 28ms/step - loss: 2.4059 - accuracy: 0.3000 - val_loss: 7.5581 - val_accuracy: 0.0700\n",
      "Epoch 5/20\n",
      "1500/1500 [==============================] - 42s 28ms/step - loss: 2.1462 - accuracy: 0.3647 - val_loss: 11.5792 - val_accuracy: 0.0400\n",
      "Epoch 6/20\n",
      "1500/1500 [==============================] - 42s 28ms/step - loss: 1.8999 - accuracy: 0.4227 - val_loss: 9.2781 - val_accuracy: 0.0450\n",
      "Epoch 7/20\n",
      "1500/1500 [==============================] - 42s 28ms/step - loss: 1.7481 - accuracy: 0.4767 - val_loss: 10.1951 - val_accuracy: 0.0550\n",
      "Epoch 8/20\n",
      "1500/1500 [==============================] - 42s 28ms/step - loss: 1.5397 - accuracy: 0.5280 - val_loss: 9.4823 - val_accuracy: 0.0500\n",
      "Epoch 9/20\n",
      "1500/1500 [==============================] - 42s 28ms/step - loss: 1.5034 - accuracy: 0.5453 - val_loss: 8.4254 - val_accuracy: 0.0900\n",
      "Epoch 10/20\n",
      "1500/1500 [==============================] - 42s 28ms/step - loss: 1.3224 - accuracy: 0.5947 - val_loss: 8.8656 - val_accuracy: 0.0750\n",
      "Epoch 11/20\n",
      "1500/1500 [==============================] - 42s 28ms/step - loss: 1.2135 - accuracy: 0.6280 - val_loss: 8.2556 - val_accuracy: 0.0800\n",
      "Epoch 12/20\n",
      "1500/1500 [==============================] - 42s 28ms/step - loss: 1.1015 - accuracy: 0.6553 - val_loss: 8.0576 - val_accuracy: 0.0850\n",
      "Epoch 13/20\n",
      "1500/1500 [==============================] - 42s 28ms/step - loss: 0.9908 - accuracy: 0.6993 - val_loss: 6.4868 - val_accuracy: 0.1050\n",
      "Epoch 14/20\n",
      "1500/1500 [==============================] - 42s 28ms/step - loss: 0.8975 - accuracy: 0.7187 - val_loss: 9.6627 - val_accuracy: 0.0550\n",
      "Epoch 15/20\n",
      "1500/1500 [==============================] - 42s 28ms/step - loss: 0.8134 - accuracy: 0.7467 - val_loss: 9.3001 - val_accuracy: 0.0700\n",
      "Epoch 16/20\n",
      "1500/1500 [==============================] - 42s 28ms/step - loss: 0.7332 - accuracy: 0.7760 - val_loss: 8.6070 - val_accuracy: 0.0900\n",
      "Epoch 17/20\n",
      "1500/1500 [==============================] - 42s 28ms/step - loss: 0.6584 - accuracy: 0.7933 - val_loss: 9.1687 - val_accuracy: 0.0850\n",
      "Epoch 18/20\n",
      "1500/1500 [==============================] - 42s 28ms/step - loss: 0.5795 - accuracy: 0.8187 - val_loss: 8.1001 - val_accuracy: 0.1000\n",
      "Epoch 19/20\n",
      "1500/1500 [==============================] - 42s 28ms/step - loss: 0.5378 - accuracy: 0.8407 - val_loss: 9.9678 - val_accuracy: 0.0750\n",
      "Epoch 20/20\n",
      "1500/1500 [==============================] - 42s 28ms/step - loss: 0.4737 - accuracy: 0.8513 - val_loss: 8.7355 - val_accuracy: 0.0850\n"
     ]
    }
   ],
   "source": [
    "densenetmodel_callbacks = [ModelCheckpoint('./models/densenet.h5', monitor='val_loss', verbose=0, \n",
    "                    save_best_only=True, save_weights_only=False, mode='auto', period=1)]\n",
    "\n",
    "densenetmodel_history = densenetmodel.fit(x_train_,\n",
    "          y_train_, \n",
    "          epochs=20, \n",
    "          verbose=1,\n",
    "          batch_size=32,\n",
    "          validation_data=(x_val_, y_val_),\n",
    "          callbacks=densenetmodel_callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load in augmented data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_aug = []\n",
    "y_train_aug = []\n",
    "\n",
    "for name in glob.glob('./ESC-50-master/augmented_audio/*'):\n",
    "    y, sr = librosa.load(name, duration=4.67)  \n",
    "    ps = librosa.feature.melspectrogram(y=y, sr=sr)\n",
    "    assert ps.shape == (128, 202)\n",
    "    x_train_aug.append(ps)\n",
    "    y_train_aug.append(int(name[32:34]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_aug_ = np.array([x.reshape( (128, 202, 1) ) for x in x_train_aug])\n",
    "y_train_aug_ = np.array(keras.utils.to_categorical(y_train_aug, 50))\n",
    "\n",
    "x_train_all = np.concatenate((x_train_, x_train_aug_), axis=0)\n",
    "y_train_all = np.concatenate((y_train_, y_train_aug_), axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train on augmented training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = keras.applications.resnet_v2.ResNet50V2(include_top=True, weights=None, input_tensor=None, input_shape=(128,202,1), pooling=None, classes=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4500 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "4500/4500 [==============================] - 105s 23ms/step - loss: 3.6167 - accuracy: 0.0838 - val_loss: 4.0843 - val_accuracy: 0.0650\n",
      "Epoch 2/20\n",
      "4500/4500 [==============================] - 91s 20ms/step - loss: 2.7641 - accuracy: 0.2191 - val_loss: 7.9894 - val_accuracy: 0.0550\n",
      "Epoch 3/20\n",
      "4500/4500 [==============================] - 91s 20ms/step - loss: 2.1061 - accuracy: 0.3818 - val_loss: 6.5006 - val_accuracy: 0.0900\n",
      "Epoch 4/20\n",
      "4500/4500 [==============================] - 91s 20ms/step - loss: 1.6293 - accuracy: 0.5122 - val_loss: 15.9970 - val_accuracy: 0.0750\n",
      "Epoch 5/20\n",
      "4500/4500 [==============================] - 91s 20ms/step - loss: 1.2828 - accuracy: 0.6151 - val_loss: 13.8068 - val_accuracy: 0.0550\n",
      "Epoch 6/20\n",
      "4500/4500 [==============================] - 91s 20ms/step - loss: 0.9666 - accuracy: 0.7011 - val_loss: 9.9212 - val_accuracy: 0.0850\n",
      "Epoch 7/20\n",
      "4500/4500 [==============================] - 91s 20ms/step - loss: 0.6873 - accuracy: 0.7884 - val_loss: 11.3353 - val_accuracy: 0.0950\n",
      "Epoch 8/20\n",
      "4500/4500 [==============================] - 91s 20ms/step - loss: 0.5063 - accuracy: 0.8407 - val_loss: 8.0671 - val_accuracy: 0.1350\n",
      "Epoch 9/20\n",
      "4500/4500 [==============================] - 91s 20ms/step - loss: 0.4245 - accuracy: 0.8698 - val_loss: 14.1472 - val_accuracy: 0.0750\n",
      "Epoch 10/20\n",
      "4500/4500 [==============================] - 91s 20ms/step - loss: 0.3234 - accuracy: 0.9036 - val_loss: 11.1298 - val_accuracy: 0.0950\n",
      "Epoch 11/20\n",
      "4500/4500 [==============================] - 91s 20ms/step - loss: 0.2386 - accuracy: 0.9269 - val_loss: 11.1508 - val_accuracy: 0.1150\n",
      "Epoch 12/20\n",
      "4500/4500 [==============================] - 91s 20ms/step - loss: 0.1820 - accuracy: 0.9478 - val_loss: 12.9948 - val_accuracy: 0.0950\n",
      "Epoch 13/20\n",
      "4500/4500 [==============================] - 91s 20ms/step - loss: 0.1550 - accuracy: 0.9567 - val_loss: 9.6818 - val_accuracy: 0.1050\n",
      "Epoch 14/20\n",
      "4500/4500 [==============================] - 91s 20ms/step - loss: 0.1183 - accuracy: 0.9649 - val_loss: 12.6625 - val_accuracy: 0.1050\n",
      "Epoch 15/20\n",
      "4500/4500 [==============================] - 91s 20ms/step - loss: 0.1152 - accuracy: 0.9673 - val_loss: 12.9869 - val_accuracy: 0.1000\n",
      "Epoch 16/20\n",
      "4500/4500 [==============================] - 91s 20ms/step - loss: 0.1075 - accuracy: 0.9656 - val_loss: 13.8378 - val_accuracy: 0.1250\n",
      "Epoch 17/20\n",
      "4500/4500 [==============================] - 91s 20ms/step - loss: 0.0817 - accuracy: 0.9787 - val_loss: 9.8800 - val_accuracy: 0.1000\n",
      "Epoch 18/20\n",
      "4500/4500 [==============================] - 91s 20ms/step - loss: 0.0501 - accuracy: 0.9876 - val_loss: 10.4754 - val_accuracy: 0.1150\n",
      "Epoch 19/20\n",
      "4500/4500 [==============================] - 91s 20ms/step - loss: 0.0720 - accuracy: 0.9816 - val_loss: 7.1119 - val_accuracy: 0.2000\n",
      "Epoch 20/20\n",
      "4500/4500 [==============================] - 91s 20ms/step - loss: 0.0878 - accuracy: 0.9729 - val_loss: 14.0250 - val_accuracy: 0.1050\n"
     ]
    }
   ],
   "source": [
    "callbacks2 = [ModelCheckpoint('./models/resnet50v2aug-dn.h5', monitor='val_loss', verbose=0, \n",
    "                    save_best_only=True, save_weights_only=False, mode='auto', period=1)]\n",
    "\n",
    "history2 = model2.fit(x_train_all,\n",
    "          y_train_all, \n",
    "          epochs=20, \n",
    "          verbose=1,\n",
    "          batch_size=32,\n",
    "          validation_data=(x_val_, y_val_),\n",
    "          callbacks=callbacks2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg16modelaug = keras.applications.vgg16.VGG16(include_top=True, weights=None, input_tensor=None, input_shape=(128,202,1), pooling=None, classes=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg16modelaug.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 13500 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "13500/13500 [==============================] - 233s 17ms/step - loss: 3.8393 - accuracy: 0.0541 - val_loss: 3.0061 - val_accuracy: 0.1600\n",
      "Epoch 2/20\n",
      "13500/13500 [==============================] - 228s 17ms/step - loss: 2.4923 - accuracy: 0.2611 - val_loss: 2.5461 - val_accuracy: 0.3200\n",
      "Epoch 3/20\n",
      "13500/13500 [==============================] - 228s 17ms/step - loss: 1.5409 - accuracy: 0.5114 - val_loss: 2.5559 - val_accuracy: 0.3900\n",
      "Epoch 4/20\n",
      "13500/13500 [==============================] - 228s 17ms/step - loss: 0.7935 - accuracy: 0.7409 - val_loss: 3.2445 - val_accuracy: 0.4050\n",
      "Epoch 5/20\n",
      "13500/13500 [==============================] - 228s 17ms/step - loss: 0.4046 - accuracy: 0.8668 - val_loss: 4.3076 - val_accuracy: 0.3850\n",
      "Epoch 6/20\n",
      "13500/13500 [==============================] - 227s 17ms/step - loss: 0.2582 - accuracy: 0.9190 - val_loss: 3.8487 - val_accuracy: 0.3850\n",
      "Epoch 7/20\n",
      "13500/13500 [==============================] - 227s 17ms/step - loss: 0.1942 - accuracy: 0.9396 - val_loss: 4.4647 - val_accuracy: 0.4150\n",
      "Epoch 8/20\n",
      "13500/13500 [==============================] - 228s 17ms/step - loss: 0.1132 - accuracy: 0.9644 - val_loss: 5.4070 - val_accuracy: 0.4000\n",
      "Epoch 9/20\n",
      "13500/13500 [==============================] - 228s 17ms/step - loss: 0.1571 - accuracy: 0.9570 - val_loss: 4.4549 - val_accuracy: 0.4050\n",
      "Epoch 10/20\n",
      "13500/13500 [==============================] - 227s 17ms/step - loss: 0.1295 - accuracy: 0.9616 - val_loss: 4.7995 - val_accuracy: 0.4600\n",
      "Epoch 11/20\n",
      "13500/13500 [==============================] - 227s 17ms/step - loss: 0.0952 - accuracy: 0.9717 - val_loss: 4.9723 - val_accuracy: 0.4500\n",
      "Epoch 12/20\n",
      "13500/13500 [==============================] - 228s 17ms/step - loss: 0.1352 - accuracy: 0.9627 - val_loss: 4.6492 - val_accuracy: 0.4650\n",
      "Epoch 13/20\n",
      "13500/13500 [==============================] - 227s 17ms/step - loss: 0.1785 - accuracy: 0.9601 - val_loss: 4.9692 - val_accuracy: 0.4250\n",
      "Epoch 14/20\n",
      "13500/13500 [==============================] - 227s 17ms/step - loss: 0.0877 - accuracy: 0.9756 - val_loss: 5.0941 - val_accuracy: 0.4100\n",
      "Epoch 15/20\n",
      "13500/13500 [==============================] - 227s 17ms/step - loss: 0.1190 - accuracy: 0.9747 - val_loss: 4.7754 - val_accuracy: 0.3700\n",
      "Epoch 16/20\n",
      "13500/13500 [==============================] - 227s 17ms/step - loss: 0.1477 - accuracy: 0.9665 - val_loss: 4.2805 - val_accuracy: 0.3900\n",
      "Epoch 17/20\n",
      "13500/13500 [==============================] - 227s 17ms/step - loss: 0.0565 - accuracy: 0.9847 - val_loss: 5.0545 - val_accuracy: 0.4050\n",
      "Epoch 18/20\n",
      "13500/13500 [==============================] - 227s 17ms/step - loss: 0.0556 - accuracy: 0.9856 - val_loss: 5.1181 - val_accuracy: 0.3750\n",
      "Epoch 19/20\n",
      "13500/13500 [==============================] - 227s 17ms/step - loss: 0.0588 - accuracy: 0.9831 - val_loss: 5.7273 - val_accuracy: 0.3550\n",
      "Epoch 20/20\n",
      "13500/13500 [==============================] - 227s 17ms/step - loss: 0.0428 - accuracy: 0.9879 - val_loss: 5.2523 - val_accuracy: 0.4050\n"
     ]
    }
   ],
   "source": [
    "vgg16modelaug_callbacks = [ModelCheckpoint('./models/vgg16aug.h5', monitor='val_loss', verbose=0, \n",
    "                    save_best_only=True, save_weights_only=False, mode='auto', period=1)]\n",
    "\n",
    "vgg16modelaug_history = vgg16modelaug.fit(x_train_all,\n",
    "          y_train_all, \n",
    "          epochs=20, \n",
    "          verbose=1,\n",
    "          batch_size=32,\n",
    "          validation_data=(x_val_, y_val_),\n",
    "          callbacks=vgg16modelaug_callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "mobilenetmodelaug = keras.applications.mobilenet.MobileNet(include_top=True, weights=None, input_tensor=None, input_shape=(128,202,1), pooling=None, classes=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "mobilenetmodelaug.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7500 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "7500/7500 [==============================] - 76s 10ms/step - loss: 2.6349 - accuracy: 0.2673 - val_loss: 6.0313 - val_accuracy: 0.0200\n",
      "Epoch 2/20\n",
      "7500/7500 [==============================] - 69s 9ms/step - loss: 1.3525 - accuracy: 0.5856 - val_loss: 7.8780 - val_accuracy: 0.0200\n",
      "Epoch 3/20\n",
      "7500/7500 [==============================] - 69s 9ms/step - loss: 0.7871 - accuracy: 0.7512 - val_loss: 8.9965 - val_accuracy: 0.0550\n",
      "Epoch 4/20\n",
      "7500/7500 [==============================] - 69s 9ms/step - loss: 0.4455 - accuracy: 0.8592 - val_loss: 7.5670 - val_accuracy: 0.1200\n",
      "Epoch 5/20\n",
      "7500/7500 [==============================] - 69s 9ms/step - loss: 0.2697 - accuracy: 0.9165 - val_loss: 8.7141 - val_accuracy: 0.1050\n",
      "Epoch 6/20\n",
      "7500/7500 [==============================] - 69s 9ms/step - loss: 0.2022 - accuracy: 0.9403 - val_loss: 9.1520 - val_accuracy: 0.1200\n",
      "Epoch 7/20\n",
      "7500/7500 [==============================] - 69s 9ms/step - loss: 0.1385 - accuracy: 0.9580 - val_loss: 8.6357 - val_accuracy: 0.1400\n",
      "Epoch 8/20\n",
      "7500/7500 [==============================] - 69s 9ms/step - loss: 0.1160 - accuracy: 0.9655 - val_loss: 10.6410 - val_accuracy: 0.0850\n",
      "Epoch 9/20\n",
      "7500/7500 [==============================] - 69s 9ms/step - loss: 0.1255 - accuracy: 0.9611 - val_loss: 12.4653 - val_accuracy: 0.0600\n",
      "Epoch 10/20\n",
      "7500/7500 [==============================] - 69s 9ms/step - loss: 0.1390 - accuracy: 0.9568 - val_loss: 12.8155 - val_accuracy: 0.0900\n",
      "Epoch 11/20\n",
      "7500/7500 [==============================] - 69s 9ms/step - loss: 0.0922 - accuracy: 0.9740 - val_loss: 10.1464 - val_accuracy: 0.0850\n",
      "Epoch 12/20\n",
      "7500/7500 [==============================] - 69s 9ms/step - loss: 0.0761 - accuracy: 0.9772 - val_loss: 13.9929 - val_accuracy: 0.0900\n",
      "Epoch 13/20\n",
      "7500/7500 [==============================] - 69s 9ms/step - loss: 0.0757 - accuracy: 0.9787 - val_loss: 11.7330 - val_accuracy: 0.1200\n",
      "Epoch 14/20\n",
      "7500/7500 [==============================] - 69s 9ms/step - loss: 0.1224 - accuracy: 0.9600 - val_loss: 11.9200 - val_accuracy: 0.1100\n",
      "Epoch 15/20\n",
      "7500/7500 [==============================] - 69s 9ms/step - loss: 0.0802 - accuracy: 0.9759 - val_loss: 13.6003 - val_accuracy: 0.0800\n",
      "Epoch 16/20\n",
      "7500/7500 [==============================] - 69s 9ms/step - loss: 0.0975 - accuracy: 0.9703 - val_loss: 7.9300 - val_accuracy: 0.2050\n",
      "Epoch 17/20\n",
      "7500/7500 [==============================] - 69s 9ms/step - loss: 0.0644 - accuracy: 0.9825 - val_loss: 13.6038 - val_accuracy: 0.0600\n",
      "Epoch 18/20\n",
      "7500/7500 [==============================] - 69s 9ms/step - loss: 0.0747 - accuracy: 0.9773 - val_loss: 10.5389 - val_accuracy: 0.1200\n",
      "Epoch 19/20\n",
      "7500/7500 [==============================] - 69s 9ms/step - loss: 0.0889 - accuracy: 0.9716 - val_loss: 11.3674 - val_accuracy: 0.0850\n",
      "Epoch 20/20\n",
      "7500/7500 [==============================] - 69s 9ms/step - loss: 0.0902 - accuracy: 0.9731 - val_loss: 10.2902 - val_accuracy: 0.1250\n"
     ]
    }
   ],
   "source": [
    "mobilenetmodelaug_callbacks = [ModelCheckpoint('./models/mobilenetaug-ps.h5', monitor='val_loss', verbose=0, \n",
    "                    save_best_only=True, save_weights_only=False, mode='auto', period=1)]\n",
    "\n",
    "mobilenetmodelaug_history = mobilenetmodelaug.fit(x_train_all,\n",
    "          y_train_all, \n",
    "          epochs=20, \n",
    "          verbose=1,\n",
    "          batch_size=32,\n",
    "          validation_data=(x_val_, y_val_),\n",
    "          callbacks=mobilenetmodelaug_callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "densenetmodelaug = keras.applications.densenet.DenseNet121(include_top=True, weights=None, input_tensor=None, input_shape=(128,202,1), pooling=None, classes=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "densenetmodelaug.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4500 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "4500/4500 [==============================] - 158s 35ms/step - loss: 3.2843 - accuracy: 0.1424 - val_loss: 3.7746 - val_accuracy: 0.0950\n",
      "Epoch 2/20\n",
      "4500/4500 [==============================] - 123s 27ms/step - loss: 2.2470 - accuracy: 0.3418 - val_loss: 6.1724 - val_accuracy: 0.0600\n",
      "Epoch 3/20\n",
      "4500/4500 [==============================] - 123s 27ms/step - loss: 1.6659 - accuracy: 0.4929 - val_loss: 7.6404 - val_accuracy: 0.0650\n",
      "Epoch 4/20\n",
      "4500/4500 [==============================] - 123s 27ms/step - loss: 1.2642 - accuracy: 0.6102 - val_loss: 8.9706 - val_accuracy: 0.0650\n",
      "Epoch 5/20\n",
      "4500/4500 [==============================] - 123s 27ms/step - loss: 0.9067 - accuracy: 0.7209 - val_loss: 8.5315 - val_accuracy: 0.0750\n",
      "Epoch 6/20\n",
      "4500/4500 [==============================] - 123s 27ms/step - loss: 0.7054 - accuracy: 0.7836 - val_loss: 6.9971 - val_accuracy: 0.1200\n",
      "Epoch 7/20\n",
      "4500/4500 [==============================] - 123s 27ms/step - loss: 0.5253 - accuracy: 0.8396 - val_loss: 4.9901 - val_accuracy: 0.2000\n",
      "Epoch 8/20\n",
      "4500/4500 [==============================] - 123s 27ms/step - loss: 0.3852 - accuracy: 0.8811 - val_loss: 7.2058 - val_accuracy: 0.1350\n",
      "Epoch 9/20\n",
      "4500/4500 [==============================] - 123s 27ms/step - loss: 0.3029 - accuracy: 0.9076 - val_loss: 5.0997 - val_accuracy: 0.2900\n",
      "Epoch 10/20\n",
      "4500/4500 [==============================] - 123s 27ms/step - loss: 0.2749 - accuracy: 0.9169 - val_loss: 7.0998 - val_accuracy: 0.1900\n",
      "Epoch 11/20\n",
      "4500/4500 [==============================] - 123s 27ms/step - loss: 0.1722 - accuracy: 0.9518 - val_loss: 7.7844 - val_accuracy: 0.1750\n",
      "Epoch 12/20\n",
      "4500/4500 [==============================] - 123s 27ms/step - loss: 0.1352 - accuracy: 0.9638 - val_loss: 4.5493 - val_accuracy: 0.2550\n",
      "Epoch 13/20\n",
      "4500/4500 [==============================] - 123s 27ms/step - loss: 0.1156 - accuracy: 0.9707 - val_loss: 2.6755 - val_accuracy: 0.3950\n",
      "Epoch 14/20\n",
      "4500/4500 [==============================] - 123s 27ms/step - loss: 0.1925 - accuracy: 0.9400 - val_loss: 4.1941 - val_accuracy: 0.3050\n",
      "Epoch 15/20\n",
      "4500/4500 [==============================] - 123s 27ms/step - loss: 0.0702 - accuracy: 0.9829 - val_loss: 4.4087 - val_accuracy: 0.3150\n",
      "Epoch 16/20\n",
      "4500/4500 [==============================] - 123s 27ms/step - loss: 0.0691 - accuracy: 0.9807 - val_loss: 4.6630 - val_accuracy: 0.3300\n",
      "Epoch 17/20\n",
      "4500/4500 [==============================] - 123s 27ms/step - loss: 0.1030 - accuracy: 0.9698 - val_loss: 4.6867 - val_accuracy: 0.2600\n",
      "Epoch 18/20\n",
      "4500/4500 [==============================] - 123s 27ms/step - loss: 0.0802 - accuracy: 0.9789 - val_loss: 5.8303 - val_accuracy: 0.1900\n",
      "Epoch 19/20\n",
      "4500/4500 [==============================] - 123s 27ms/step - loss: 0.0869 - accuracy: 0.9749 - val_loss: 2.0336 - val_accuracy: 0.5400\n",
      "Epoch 20/20\n",
      "4500/4500 [==============================] - 123s 27ms/step - loss: 0.1122 - accuracy: 0.9662 - val_loss: 2.8411 - val_accuracy: 0.4250\n"
     ]
    }
   ],
   "source": [
    "densenetmodelaug_callbacks = [ModelCheckpoint('./models/densenetaug-dn.h5', monitor='val_loss', verbose=0, \n",
    "                    save_best_only=True, save_weights_only=False, mode='auto', period=1)]\n",
    "\n",
    "densenetmodelaug_history = densenetmodelaug.fit(x_train_all,\n",
    "          y_train_all, \n",
    "          epochs=20, \n",
    "          verbose=1,\n",
    "          batch_size=32,\n",
    "          validation_data=(x_val_, y_val_),\n",
    "          callbacks=densenetmodelaug_callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test models on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(x_test_, y_test_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.evaluate(x_test_, y_test_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_metrics(predictions, groun_truth):\n",
    "    average_type = 'macro'\n",
    "\n",
    "    accuracy = accuracy_score(predictions, groun_truth)\n",
    "    precision = precision_score(predictions, groun_truth, average=average_type)\n",
    "    recall = recall_score(predictions, groun_truth, average=average_type)\n",
    "    f1 = f1_score(predictions, groun_truth, average=average_type)\n",
    "    \n",
    "    print('acc: ', accuracy)\n",
    "    print('pre: ', precision)\n",
    "    print('rec: ', recall)\n",
    "    print('f1 : ', f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mobilenet.h5\n",
      "acc:  0.02\n",
      "pre:  0.02\n",
      "rec:  0.0004\n",
      "f1 :  0.000784313725490196\n",
      "resnet50v2.h5\n",
      "acc:  0.06\n",
      "pre:  0.06\n",
      "rec:  0.024224117906203692\n",
      "f1 :  0.02497138459223767\n",
      "vgg16.h5\n",
      "acc:  0.33666666666666667\n",
      "pre:  0.33666666666666667\n",
      "rec:  0.37220202020202015\n",
      "f1 :  0.3257581103273703\n"
     ]
    }
   ],
   "source": [
    "model_names = ['mobilenet.h5', 'resnet50v2.h5', 'vgg16.h5']\n",
    "\n",
    "for name in model_names:\n",
    "    print(name)\n",
    "    \n",
    "    loaded_model = load_model('./models/' + name)\n",
    "    predictions = loaded_model.predict(x_test_, verbose=0)\n",
    "    loaded_model_predictions = []\n",
    "    \n",
    "    for prediction in predictions:\n",
    "        loaded_model_predictions.append(np.argmax(prediction))\n",
    "    \n",
    "    print_metrics(loaded_model_predictions, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_names = ['densenetaug.h5', 'mobilenetaug.h5', 'resnet50v2aug.h5', 'vgg16aug.h5']\n",
    "\n",
    "for name in model_names:\n",
    "    print(name)\n",
    "    \n",
    "    loaded_model = load_model('./models/' + name)\n",
    "    predictions = loaded_model.predict(x_test_, verbose=0)\n",
    "    loaded_model_predictions = []\n",
    "    \n",
    "    for prediction in predictions:\n",
    "        loaded_model_predictions.append(np.argmax(prediction))\n",
    "    \n",
    "    print_metrics(loaded_model_predictions, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "densenetaug-ps.h5\n",
      "acc:  0.07333333333333333\n",
      "pre:  0.07333333333333333\n",
      "rec:  0.06016859195468821\n",
      "f1 :  0.050130142414854896\n",
      "mobilenetaug-ps.h5\n",
      "acc:  0.02\n",
      "pre:  0.02\n",
      "rec:  0.0004\n",
      "f1 :  0.000784313725490196\n",
      "resnet50v2aug-ps.h5\n",
      "acc:  0.07\n",
      "pre:  0.07\n",
      "rec:  0.03659095526243234\n",
      "f1 :  0.028946076903971645\n",
      "vgg16aug-ps.h5\n",
      "acc:  0.4\n",
      "pre:  0.4\n",
      "rec:  0.43108080808080806\n",
      "f1 :  0.3832570109628934\n"
     ]
    }
   ],
   "source": [
    "model_names = ['densenetaug-ps.h5', 'mobilenetaug-ps.h5', 'resnet50v2aug-ps.h5', 'vgg16aug-ps.h5']\n",
    "\n",
    "for name in model_names:\n",
    "    print(name)\n",
    "    \n",
    "    loaded_model = load_model('./models/' + name)\n",
    "    predictions = loaded_model.predict(x_test_, verbose=0)\n",
    "    loaded_model_predictions = []\n",
    "    \n",
    "    for prediction in predictions:\n",
    "        loaded_model_predictions.append(np.argmax(prediction))\n",
    "    \n",
    "    print_metrics(loaded_model_predictions, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "densenetaug-ts.h5\n",
      "acc:  0.11333333333333333\n",
      "pre:  0.11333333333333333\n",
      "rec:  0.1045859553123575\n",
      "f1 :  0.08372826908541194\n",
      "mobilenetaug-ts.h5\n",
      "acc:  0.02\n",
      "pre:  0.02\n",
      "rec:  0.0004\n",
      "f1 :  0.000784313725490196\n",
      "resnet50v2aug-ts.h5\n",
      "acc:  0.12666666666666668\n",
      "pre:  0.12666666666666665\n",
      "rec:  0.07068743265479437\n",
      "f1 :  0.06786451076727877\n",
      "vgg16aug-ts.h5\n",
      "acc:  0.3933333333333333\n",
      "pre:  0.3933333333333333\n",
      "rec:  0.40639789295671647\n",
      "f1 :  0.36680673613639014\n"
     ]
    }
   ],
   "source": [
    "model_names = ['densenetaug-ts.h5', 'mobilenetaug-ts.h5', 'resnet50v2aug-ts.h5', 'vgg16aug-ts.h5']\n",
    "\n",
    "for name in model_names:\n",
    "    print(name)\n",
    "    \n",
    "    loaded_model = load_model('./models/' + name)\n",
    "    predictions = loaded_model.predict(x_test_, verbose=0)\n",
    "    loaded_model_predictions = []\n",
    "    \n",
    "    for prediction in predictions:\n",
    "        loaded_model_predictions.append(np.argmax(prediction))\n",
    "    \n",
    "    print_metrics(loaded_model_predictions, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mobilenetaug-dn.h5\n",
      "acc:  0.55\n",
      "pre:  0.55\n",
      "rec:  0.6231434676434676\n",
      "f1 :  0.5467541230699126\n",
      "resnet50v2aug-dn.h5\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32mc:\\programdata\\miniconda3\\lib\\site-packages\\tensorflow_core\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mget_attr\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   2325\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mc_api_util\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtf_buffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mbuf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2326\u001b[1;33m         \u001b[0mc_api\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_OperationGetAttrValueProto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_c_op\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbuf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2327\u001b[0m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mc_api\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbuf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: Operation 'conv3_block1_2_bn_1/batchnorm/mul_1' has no attr named '_XlaCompile'.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\programdata\\miniconda3\\lib\\site-packages\\tensorflow_core\\python\\ops\\gradients_util.py\u001b[0m in \u001b[0;36m_MaybeCompile\u001b[1;34m(scope, op, func, grad_fn)\u001b[0m\n\u001b[0;32m    330\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 331\u001b[1;33m       \u001b[0mxla_compile\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_attr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"_XlaCompile\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    332\u001b[0m       xla_separate_compiled_gradients = op.get_attr(\n",
      "\u001b[1;32mc:\\programdata\\miniconda3\\lib\\site-packages\\tensorflow_core\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mget_attr\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   2329\u001b[0m       \u001b[1;31m# Convert to ValueError for backwards compatibility.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2330\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2331\u001b[0m     \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mattr_value_pb2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mAttrValue\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Operation 'conv3_block1_2_bn_1/batchnorm/mul_1' has no attr named '_XlaCompile'.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-95-13b58cd9ebc1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m     \u001b[0mloaded_model\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'./models/'\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m     \u001b[0mpredictions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mloaded_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_test_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0mloaded_model_predictions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\programdata\\miniconda3\\lib\\site-packages\\keras\\engine\\saving.py\u001b[0m in \u001b[0;36mload_wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    490\u001b[0m                 \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mremove\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtmp_filepath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    491\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mres\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 492\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mload_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    493\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    494\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mload_wrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\programdata\\miniconda3\\lib\\site-packages\\keras\\engine\\saving.py\u001b[0m in \u001b[0;36mload_model\u001b[1;34m(filepath, custom_objects, compile)\u001b[0m\n\u001b[0;32m    582\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mH5Dict\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_supported_type\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    583\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mH5Dict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'r'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mh5dict\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 584\u001b[1;33m             \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_deserialize_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mh5dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcustom_objects\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcompile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    585\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'write'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mcallable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    586\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mload_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mh5file\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\programdata\\miniconda3\\lib\\site-packages\\keras\\engine\\saving.py\u001b[0m in \u001b[0;36m_deserialize_model\u001b[1;34m(h5dict, custom_objects, compile)\u001b[0m\n\u001b[0;32m    372\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;34m'optimizer_weights'\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mh5dict\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    373\u001b[0m             \u001b[1;31m# Build train function (to get weight updates).\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 374\u001b[1;33m             \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    375\u001b[0m             \u001b[0moptimizer_weights_group\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mh5dict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'optimizer_weights'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    376\u001b[0m             optimizer_weight_names = [\n",
      "\u001b[1;32mc:\\programdata\\miniconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_make_train_function\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    314\u001b[0m                     training_updates = self.optimizer.get_updates(\n\u001b[0;32m    315\u001b[0m                         \u001b[0mparams\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_collected_trainable_weights\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 316\u001b[1;33m                         loss=self.total_loss)\n\u001b[0m\u001b[0;32m    317\u001b[0m                 \u001b[0mupdates\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdates\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mtraining_updates\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    318\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\programdata\\miniconda3\\lib\\site-packages\\keras\\legacy\\interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[0;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[1;32m---> 91\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\programdata\\miniconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36msymbolic_fn_wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     73\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0m_SYMBOLIC_SCOPE\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mget_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_default\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 75\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     76\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     77\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\programdata\\miniconda3\\lib\\site-packages\\keras\\optimizers.py\u001b[0m in \u001b[0;36mget_updates\u001b[1;34m(self, loss, params)\u001b[0m\n\u001b[0;32m    502\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mK\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msymbolic\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    503\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget_updates\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 504\u001b[1;33m         \u001b[0mgrads\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_gradients\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    505\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdates\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mK\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate_add\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miterations\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    506\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\programdata\\miniconda3\\lib\\site-packages\\keras\\optimizers.py\u001b[0m in \u001b[0;36mget_gradients\u001b[1;34m(self, loss, params)\u001b[0m\n\u001b[0;32m     89\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     90\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget_gradients\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 91\u001b[1;33m         \u001b[0mgrads\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mK\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgradients\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     92\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0many\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mgrads\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m             raise ValueError('An operation has `None` for gradient. '\n",
      "\u001b[1;32mc:\\programdata\\miniconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36msymbolic_fn_wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     73\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0m_SYMBOLIC_SCOPE\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mget_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_default\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 75\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     76\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     77\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\programdata\\miniconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36mgradients\u001b[1;34m(loss, variables)\u001b[0m\n\u001b[0;32m   3023\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0m_is_tf_1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3024\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgradients\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvariables\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolocate_gradients_with_ops\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3025\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgradients\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvariables\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3026\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3027\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\programdata\\miniconda3\\lib\\site-packages\\tensorflow_core\\python\\ops\\gradients_impl.py\u001b[0m in \u001b[0;36mgradients_v2\u001b[1;34m(ys, xs, grad_ys, name, gate_gradients, aggregation_method, stop_gradients, unconnected_gradients)\u001b[0m\n\u001b[0;32m    272\u001b[0m         \u001b[0mys\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mxs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_ys\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgate_gradients\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    273\u001b[0m         \u001b[0maggregation_method\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstop_gradients\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 274\u001b[1;33m         unconnected_gradients)\n\u001b[0m\u001b[0;32m    275\u001b[0m   \u001b[1;31m# pylint: enable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    276\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\programdata\\miniconda3\\lib\\site-packages\\tensorflow_core\\python\\ops\\gradients_util.py\u001b[0m in \u001b[0;36m_GradientsHelper\u001b[1;34m(ys, xs, grad_ys, name, colocate_gradients_with_ops, gate_gradients, aggregation_method, stop_gradients, unconnected_gradients, src_graph)\u001b[0m\n\u001b[0;32m    667\u001b[0m                 \u001b[1;31m# functions.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    668\u001b[0m                 in_grads = _MaybeCompile(grad_scope, op, func_call,\n\u001b[1;32m--> 669\u001b[1;33m                                          lambda: grad_fn(op, *out_grads))\n\u001b[0m\u001b[0;32m    670\u001b[0m               \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    671\u001b[0m                 \u001b[1;31m# For function call ops, we add a 'SymbolicGradient'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\programdata\\miniconda3\\lib\\site-packages\\tensorflow_core\\python\\ops\\gradients_util.py\u001b[0m in \u001b[0;36m_MaybeCompile\u001b[1;34m(scope, op, func, grad_fn)\u001b[0m\n\u001b[0;32m    334\u001b[0m       \u001b[0mxla_scope\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_attr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"_XlaScope\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    335\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 336\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mgrad_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# Exit early\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    337\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    338\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mxla_compile\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\programdata\\miniconda3\\lib\\site-packages\\tensorflow_core\\python\\ops\\gradients_util.py\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    667\u001b[0m                 \u001b[1;31m# functions.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    668\u001b[0m                 in_grads = _MaybeCompile(grad_scope, op, func_call,\n\u001b[1;32m--> 669\u001b[1;33m                                          lambda: grad_fn(op, *out_grads))\n\u001b[0m\u001b[0;32m    670\u001b[0m               \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    671\u001b[0m                 \u001b[1;31m# For function call ops, we add a 'SymbolicGradient'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\programdata\\miniconda3\\lib\\site-packages\\tensorflow_core\\python\\ops\\math_grad.py\u001b[0m in \u001b[0;36m_MulGrad\u001b[1;34m(op, grad)\u001b[0m\n\u001b[0;32m   1240\u001b[0m   \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1241\u001b[0m     gy = array_ops.reshape(\n\u001b[1;32m-> 1242\u001b[1;33m         math_ops.reduce_sum(gen_math_ops.mul(x, grad), ry), sy)\n\u001b[0m\u001b[0;32m   1243\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mgx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1244\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\programdata\\miniconda3\\lib\\site-packages\\tensorflow_core\\python\\ops\\array_ops.py\u001b[0m in \u001b[0;36mreshape\u001b[1;34m(tensor, shape, name)\u001b[0m\n\u001b[0;32m    191\u001b[0m     \u001b[0mA\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m.\u001b[0m \u001b[0mHas\u001b[0m \u001b[0mthe\u001b[0m \u001b[0msame\u001b[0m \u001b[0mtype\u001b[0m \u001b[1;32mas\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    192\u001b[0m   \"\"\"\n\u001b[1;32m--> 193\u001b[1;33m   \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgen_array_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    194\u001b[0m   \u001b[0mtensor_util\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmaybe_set_static_shape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    195\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\programdata\\miniconda3\\lib\\site-packages\\tensorflow_core\\python\\ops\\gen_array_ops.py\u001b[0m in \u001b[0;36mreshape\u001b[1;34m(tensor, shape, name)\u001b[0m\n\u001b[0;32m   7441\u001b[0m   \u001b[1;31m# Add nodes to the TensorFlow graph.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   7442\u001b[0m   _, _, _op, _outputs = _op_def_library._apply_op_helper(\n\u001b[1;32m-> 7443\u001b[1;33m         \"Reshape\", tensor=tensor, shape=shape, name=name)\n\u001b[0m\u001b[0;32m   7444\u001b[0m   \u001b[0m_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_outputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   7445\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0m_execute\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmust_record_gradient\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\programdata\\miniconda3\\lib\\site-packages\\tensorflow_core\\python\\framework\\op_def_library.py\u001b[0m in \u001b[0;36m_apply_op_helper\u001b[1;34m(op_type_name, name, **keywords)\u001b[0m\n\u001b[0;32m    740\u001b[0m       op = g._create_op_internal(op_type_name, inputs, dtypes=None,\n\u001b[0;32m    741\u001b[0m                                  \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mscope\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_types\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 742\u001b[1;33m                                  attrs=attr_protos, op_def=op_def)\n\u001b[0m\u001b[0;32m    743\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    744\u001b[0m     \u001b[1;31m# `outputs` is returned as a separate return value so that the output\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\programdata\\miniconda3\\lib\\site-packages\\tensorflow_core\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36m_create_op_internal\u001b[1;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_device)\u001b[0m\n\u001b[0;32m    593\u001b[0m     return super(FuncGraph, self)._create_op_internal(  # pylint: disable=protected-access\n\u001b[0;32m    594\u001b[0m         \u001b[0mop_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_types\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop_def\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 595\u001b[1;33m         compute_device)\n\u001b[0m\u001b[0;32m    596\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    597\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mcapture\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\programdata\\miniconda3\\lib\\site-packages\\tensorflow_core\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m_create_op_internal\u001b[1;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_device)\u001b[0m\n\u001b[0;32m   3320\u001b[0m           \u001b[0minput_types\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3321\u001b[0m           \u001b[0moriginal_op\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_default_original_op\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3322\u001b[1;33m           op_def=op_def)\n\u001b[0m\u001b[0;32m   3323\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_create_op_helper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mret\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcompute_device\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcompute_device\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3324\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\programdata\\miniconda3\\lib\\site-packages\\tensorflow_core\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, node_def, g, inputs, output_types, control_inputs, input_types, original_op, op_def)\u001b[0m\n\u001b[0;32m   1784\u001b[0m           op_def, inputs, node_def.attr)\n\u001b[0;32m   1785\u001b[0m       self._c_op = _create_c_op(self._graph, node_def, grouped_inputs,\n\u001b[1;32m-> 1786\u001b[1;33m                                 control_input_ops)\n\u001b[0m\u001b[0;32m   1787\u001b[0m       \u001b[0mname\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_str\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1788\u001b[0m     \u001b[1;31m# pylint: enable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\programdata\\miniconda3\\lib\\site-packages\\tensorflow_core\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m_create_c_op\u001b[1;34m(graph, node_def, inputs, control_inputs)\u001b[0m\n\u001b[0;32m   1602\u001b[0m       \u001b[0mc_api\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_AddInputList\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mop_desc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_as_tf_output\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mop_input\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1603\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1604\u001b[1;33m       \u001b[0mc_api\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_AddInput\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mop_desc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop_input\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_as_tf_output\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1605\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1606\u001b[0m   \u001b[1;31m# Add control inputs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model_names = ['mobilenetaug-dn.h5', 'resnet50v2aug-dn.h5', 'vgg16aug-dn.h5']\n",
    "\n",
    "for name in model_names:\n",
    "    print(name)\n",
    "    \n",
    "    loaded_model = load_model('./models/' + name)\n",
    "    predictions = loaded_model.predict(x_test_, verbose=0)\n",
    "    loaded_model_predictions = []\n",
    "    \n",
    "    for prediction in predictions:\n",
    "        loaded_model_predictions.append(np.argmax(prediction))\n",
    "    \n",
    "    print_metrics(loaded_model_predictions, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
